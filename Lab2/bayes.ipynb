{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7JoXbPoXy_F"
   },
   "outputs": [],
   "source": [
    "pip install onedrivedownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsYE8NBYW0nk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from onedrivedownloader import download\n",
    "\n",
    "download('https://unimore365-my.sharepoint.com/:u:/g/personal/215580_unimore_it/EXhnxAKIfcdIqSRJoFc_C6EBCT6S0CNLOYFW3ShqivC46w?e=Ii4NOp',\n",
    "                                                      filename='./mnist/mnist_mnist.zip',\n",
    "                                                      unzip=True)\n",
    "\n",
    "def load_mnist_digits():\n",
    "    \"\"\"\n",
    "    Loads mnist (original, with digits).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        x_train with shape(n_train_samples, h, w)\n",
    "        y_train with shape(n_train_samples,)\n",
    "        x_test with shape(n_test_samples, h, w)\n",
    "        y_test with shape(n_test_samples,)\n",
    "    \"\"\"\n",
    "\n",
    "    x_train = np.load('mnist/x_train.npy')\n",
    "    y_train = np.load('mnist/y_train.npy')\n",
    "\n",
    "    x_test = np.load('mnist/x_test.npy')\n",
    "    y_test = np.load('mnist/y_test.npy')\n",
    "\n",
    "    label_dict = {i: str(i) for i in range(0, 10)}\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, label_dict\n",
    "\n",
    "\n",
    "def load_mnist(threshold=0.5):\n",
    "    \"\"\"\n",
    "    Loads MNIST data (either digits or fashion) and returns it binarized.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold: float\n",
    "        a threshold in [0, 1] to binarize w.r.t.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        x_train with shape(n_train_samples, h, w)\n",
    "        y_train with shape(n_train_samples,)\n",
    "        x_test with shape(n_test_samples, h, w)\n",
    "        y_test with shape(n_test_samples,)\n",
    "    \"\"\"\n",
    "\n",
    "    x_train, y_train, x_test, y_test, label_dict = load_mnist_digits()\n",
    "\n",
    "    x_train = np.float32(x_train) / 255.\n",
    "    x_train[x_train >= threshold] = 1\n",
    "    x_train[x_train < threshold] = 0\n",
    "\n",
    "    x_test = np.float32(x_test) / 255.\n",
    "    x_test[x_test >= threshold] = 1\n",
    "    x_test[x_test < threshold] = 0\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ua32NN0TYHga"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class that models a Naive Bayes Classifier\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    \"\"\"\n",
    "    Naive Bayes Classifier.\n",
    "    Training:\n",
    "    For each class, a naive likelihood model is estimated for P(X/Y),\n",
    "    and the prior probability P(Y) is computed.\n",
    "    Inference:\n",
    "    performed according with the Bayes rule:\n",
    "    P = argmax_Y (P(X/Y) * P(Y))\n",
    "    or\n",
    "    P = argmax_Y (log(P(X/Y)) + log(P(Y)))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "        \"\"\"\n",
    "\n",
    "        self._classes = None\n",
    "        self._n_classes = 0\n",
    "\n",
    "        self._eps = np.finfo(np.float32).eps\n",
    "\n",
    "        # array of classes prior probabilities\n",
    "        self._class_priors = []\n",
    "\n",
    "        # array of probabilities of a pixel being active (for each class)\n",
    "        self._pixel_probs_given_class = []\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Computes, for each class, a naive likelihood model (self._pixel_probs_given_class),\n",
    "        and a prior probability (self.class_priors).\n",
    "        Both quantities are estimated from examples X and Y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.array\n",
    "            input MNIST digits. Has shape (n_train_samples, h, w)\n",
    "        Y: np.array\n",
    "            labels for MNIST digits. Has shape (n_train_samples,)\n",
    "        \"\"\"\n",
    "        \n",
    "        self._n_classes = len(np.unique(Y))\n",
    "        self._classes = np.unique(Y)\n",
    "\n",
    "        for c in range(self._n_classes):\n",
    "             self._class_priors.append(sum(Y==c)/len(Y)) # prior\n",
    "             self._pixel_probs_given_class.append(X[Y==c].mean(0))\n",
    "\n",
    "    def predict(self, X, return_pred=False):\n",
    "        \"\"\"\n",
    "        Performs inference on test data.\n",
    "        Inference is performed according with the Bayes rule:\n",
    "        P = argmax_Y (log(P(X/Y)) + log(P(Y)) - log(P(X)))\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.array\n",
    "            MNIST test images. Has shape (n_test_samples, h, w).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prediction: np.array\n",
    "            model predictions over X. Has shape (n_test_samples,)\n",
    "        \"\"\"\n",
    "        return np.random.randint(10, size=(X.shape[0],))\n",
    "\n",
    "    @staticmethod\n",
    "    def _estimate_pixel_probabilities(images):\n",
    "        \"\"\"\n",
    "        [OPTIONAL!]\n",
    "        Estimates pixel probabilities from data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.array\n",
    "            images to estimate pixel probabilities from. Has shape (n_images, h, w)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pix_probs: np.array\n",
    "            probabilities for each pixel of being 1, estimated from images.\n",
    "            Has shape (h, w)\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def get_log_likelihood_under_model(self, images, model):\n",
    "        \"\"\"\n",
    "        [OPTIONAL!]\n",
    "        Returns the likelihood of many images under a certain model.\n",
    "        Naive:\n",
    "        the likelihood of the image is the product of the likelihood of each pixel.\n",
    "        or\n",
    "        the log-likelihood of the image is the sum of the log-likelihood of each pixel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        images: np.array\n",
    "            input images. Having shape (n_images, h, w).\n",
    "        model: np.array\n",
    "            a model of pixel probabilities, having shape (h, w)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lkl: np.array\n",
    "            the likelihood of each pixel under the model, having shape (h, w).\n",
    "        \"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa15Lpq2as0A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train, y_train, x_test, y_test, label_dict = load_mnist(threshold=0.5)\n",
    "\n",
    "print(f\"Training set -> number of examples: {len(x_train)}\")\n",
    "print(f\"Test set -> number of examples: {len(x_test)}\")\n",
    "print('-'*30)\n",
    "print(f'X -> shape: {x_train.shape}')\n",
    "print(f\"X -> dtype: {x_train.dtype}\")\n",
    "print(f\"X -> min: {x_train.min()}\")\n",
    "print(f\"X -> max: {x_train.max()}\")\n",
    "print(f\"X -> values: {np.unique(x_train)}\")\n",
    "print('-'*30)\n",
    "print(f\"Classes: {(np.unique(y_train))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fu6xDJRbyff"
   },
   "outputs": [],
   "source": [
    "num_row, num_col = 1, 10\n",
    "len_tr = len(x_train)\n",
    "f, subplots = plt.subplots(num_row, num_col, sharex='col', sharey='row')\n",
    "\n",
    "for cls in np.unique(y_train):\n",
    "    idx = np.arange(len_tr)[y_train == cls]\n",
    "    idx = np.random.choice(idx)\n",
    "    X_img = x_train[idx]\n",
    "    subplots[cls].imshow(X_img, cmap='gray',\n",
    "                       interpolation='nearest', aspect='auto')\n",
    "    subplots[cls].set_title(f'Digit {cls}', fontweight=\"bold\")\n",
    "    subplots[cls].grid(visible=False)\n",
    "    subplots[cls].axis('off')\n",
    "\n",
    "f.set_size_inches(22.5, 4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0veJlp2fNEI"
   },
   "source": [
    "**Step 1: training the Naive Bayes classifier on the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igAkkWhAfFEX"
   },
   "outputs": [],
   "source": [
    "# get the model\n",
    "nbc = NaiveBayesClassifier()\n",
    "\n",
    "# train\n",
    "nbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1aGqvp4fpDB"
   },
   "source": [
    "**Step 2: evaluating the performance of the classifier on a set of unseen data (test set).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVcK2ezWfIkX"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(targets, predictions, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    n_classes, = np.unique(targets).shape\n",
    "\n",
    "    cm = np.zeros(shape=(n_classes, n_classes), dtype=np.float32)\n",
    "    for t, p in zip(targets, predictions):\n",
    "        cm[int(t), int(p)] += 1\n",
    "\n",
    "    if normalize:\n",
    "        cm /= cm.sum(axis=1)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# test\n",
    "predictions = nbc.predict(x_test.reshape((len(x_test), -1)))\n",
    "\n",
    "# evaluate performances\n",
    "accuracy = np.sum(np.uint8(predictions == y_test)) / len(y_test)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "# show confusion matrix\n",
    "plot_confusion_matrix(targets=y_test,\n",
    "                      predictions=predictions,\n",
    "                      classes=[label_dict[l] for l in label_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXYFDINAYLpi"
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, x_test.shape[0])\n",
    "\n",
    "x = x_test[idx]\n",
    "p = predictions[idx]\n",
    "y = y_test[idx]\n",
    "\n",
    "plt.imshow(x, cmap='gray')\n",
    "plt.title('Target: {}, Prediction: {}'.format(label_dict[int(y)], label_dict[int(p)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iigFMnshb3u"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import io\n",
    "from PIL import Image as PILimage\n",
    "\n",
    "canvas_html = \"\"\"\n",
    "<canvas width=256 height=256></canvas>\n",
    "<button>Finish</button>\n",
    "<script>\n",
    "var canvas = document.querySelector('canvas')\n",
    "var ctx = canvas.getContext('2d')\n",
    "ctx.strokeStyle = \"#FFFFFF\"\n",
    "ctx.fillStyle = \"#000000\";\n",
    "ctx.fillRect(0, 0, 256, 256)\n",
    "ctx.lineWidth = %d\n",
    "var button = document.querySelector('button')\n",
    "var mouse = {x: 0, y: 0}\n",
    "\n",
    "canvas.addEventListener('mousemove', function(e) {\n",
    "  mouse.x = e.pageX - this.offsetLeft\n",
    "  mouse.y = e.pageY - this.offsetTop\n",
    "})\n",
    "canvas.onmousedown = ()=>{\n",
    "  ctx.beginPath()\n",
    "  ctx.moveTo(mouse.x, mouse.y)\n",
    "  canvas.addEventListener('mousemove', onPaint)\n",
    "}\n",
    "canvas.onmouseup = ()=>{\n",
    "  canvas.removeEventListener('mousemove', onPaint)\n",
    "}\n",
    "var onPaint = ()=>{\n",
    "  ctx.lineTo(mouse.x, mouse.y)\n",
    "  ctx.stroke()\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "  button.onclick = ()=>{\n",
    "    resolve(canvas.toDataURL('image/png'))\n",
    "  }\n",
    "})\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def draw(filename='drawing.png', line_width=5, centercrop=True):\n",
    "  display(HTML(canvas_html % (line_width, )))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  buf = io.BytesIO(binary)\n",
    "  img = PILimage.open(buf)\n",
    "  img = img.resize((28, 28), PILimage.BILINEAR)\n",
    "  img = img.convert('LA')\n",
    "  img = np.array(img)[:, :, 0]\n",
    "  img = img > 75\n",
    "\n",
    "  coords = np.argwhere(img)\n",
    "  x_min, y_min = coords.min(axis=0)\n",
    "  x_max, y_max = coords.max(axis=0)\n",
    "  cropped = img[x_min:x_max+1, y_min:y_max+1]\n",
    "\n",
    "  out_img = np.zeros((28,28))\n",
    "\n",
    "  delta_x, delta_y = (28 - cropped.shape[0]) // 2, (28 - cropped.shape[1]) // 2\n",
    "  out_img[delta_x:delta_x + cropped.shape[0], delta_y :delta_y + + cropped.shape[1]] = cropped\n",
    "\n",
    "  return out_img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGhCAuM1k5aR"
   },
   "outputs": [],
   "source": [
    "img = draw(line_width=10)\n",
    "print(img.shape, img.dtype, np.unique(img))\n",
    "plt.imshow(img, cmap='Greys_r')\n",
    "\n",
    "pred, negllk = nbc.predict(img.reshape(1, 28*28), True)\n",
    "classes_ord = np.arange(len(np.unique(y_test)))[np.argsort(negllk)]\n",
    "classes_ord = np.flip(classes_ord)\n",
    "print(f'Predicted - {pred}')\n",
    "print(f'Scores: {negllk}')\n",
    "print(f'Classes ordered by scores: {classes_ord}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GGqtBQUrYHN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a58c90aaaf62e5f8a47211752fce3a7bb3007b680eb2c05bbd7d19b8ca244527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
