{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS device not found.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "j_IIrqdCMFqP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "transforms = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.MNIST('/tmp/data', train=True, download=True, \n",
        "                               transform=transforms)\n",
        "\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True,\n",
        "                              transform=transforms)\n",
        "\n",
        "print(torch.backends.mps.is_built())\n",
        "print(torch.backends.mps.is_available())\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yHu1ajIoMr7o"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE      = 64        # number of data points in each batch\n",
        "N_EPOCHS        = 10        # times to run the model on complete data\n",
        "INPUT_DIM       = 28 * 28   # size of each input\n",
        "HIDDEN_DIM      = 256       # hidden dimension\n",
        "LATENT_DIM      = 20        # latent vector dimension\n",
        "lr              = 1e-3      # learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "MBxovLF7MtR9"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EByRRl8RMvz9"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  ''' This the encoder part of VAE'''\n",
        "\n",
        "  def __init__(self, input_dim: int, hidden_dim: int, z_dim: int):\n",
        "    '''\n",
        "    Args:\n",
        "      input_dim: A integer indicating the size of input \n",
        "        (in case of MNIST 28 * 28).\n",
        "      hidden_dim: A integer indicating the size of hidden dimension.\n",
        "      z_dim: A integer indicating the latent dimension.\n",
        "    '''\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.z_dim = z_dim\n",
        "    self.encoder = nn.Sequential(\n",
        "      nn.Linear(input_dim, hidden_dim), \n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, hidden_dim), \n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, 2*z_dim),\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    # x is of shape [batch_size, input_dim]\n",
        "\n",
        "    hidden = self.encoder(x)\n",
        "    z_mu, z_logvar = hidden[:, :self.z_dim], hidden[:, self.z_dim:]\n",
        "\n",
        "    return z_mu, z_logvar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "MYvWzg1hM0At"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  ''' This the decoder part of VAE'''\n",
        "\n",
        "  def __init__(self, z_dim: int, hidden_dim: int, output_dim: int):\n",
        "    '''\n",
        "    Args:\n",
        "        z_dim: A integer indicating the latent size.\n",
        "        hidden_dim: A integer indicating the size of hidden dimension.\n",
        "        output_dim: A integer indicating the output dimension \n",
        "          (in case of MNIST it is 28 * 28)\n",
        "    '''\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "      nn.Linear(z_dim, hidden_dim), \n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, hidden_dim), \n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_dim, output_dim),\n",
        "      nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.decoder(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb0e8m-MF_a_"
      },
      "source": [
        "# Variational AutoEncoder\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{\\mu}_x, \\boldsymbol{\\sigma}_x &= M(\\textbf{x}), \\Sigma(\\textbf{x}) && \\text{Push $\\textbf{x}$ through encoder}\n",
        "\\\\ \\\\\n",
        "\\boldsymbol{\\epsilon} &\\sim \\mathcal{N}(0, 1) && \\text{Sample noise}\n",
        "\\\\ \\\\\n",
        "\\textbf{z} &= \\boldsymbol{\\epsilon} \\boldsymbol{\\sigma}_x + \\boldsymbol{\\mu}_x  && \\text{Reparameterize}\n",
        "\\\\ \\\\\n",
        "\\textbf{x}_r &= p_{\\boldsymbol{\\theta}}(\\textbf{x} \\mid \\textbf{z}) && \\text{Push $\\textbf{z}$ through decoder}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "LrOC6YrSM85V"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "  ''' This the VAE, which takes a encoder and decoder.'''\n",
        "\n",
        "  def __init__(self, enc: Encoder, dec: Decoder):\n",
        "    super(VAE, self).__init__()\n",
        "    self.enc = enc\n",
        "    self.dec = dec\n",
        "\n",
        "  def reparameterization_trick(self, z_mu: torch.Tensor, \n",
        "                                z_logvar: torch.Tensor):\n",
        "  \n",
        "    # implement reparametrization trick\n",
        "    return z_mu + torch.exp(z_logvar) * torch.randn_like(z_mu)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    \n",
        "    # encode\n",
        "    z_mu, z_logvar = self.enc(x)\n",
        "\n",
        "    # sample z from posterior distribution\n",
        "    z_post = self.reparameterization_trick(z_mu, z_logvar)\n",
        "    \n",
        "    # decode\n",
        "    predicted = self.dec(z_post)\n",
        "\n",
        "    return predicted, z_mu, z_logvar\n",
        "\n",
        "  def sample(self, num_samples: int = 1):\n",
        "    \n",
        "    # implement sampling of num_samples datapoint\n",
        "    z = torch.randn((num_samples, LATENT_DIM), device=device)\n",
        "    return self.dec(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1s5HnYhGTWc"
      },
      "source": [
        "# ELBO computation\n",
        "\n",
        "\\begin{align}\n",
        "\\text{recon. loss} &= \\text{MSE}(\\textbf{x}, \\textbf{x}_r) \\ \\ \\text{or} \\ \\  \\text{BCE}(\\textbf{x}, \\textbf{x}_r) && \\text{Compute reconstruction loss}\n",
        "\\\\ \\\\\n",
        "\\text{var. loss} &= \\text{KL}[\\mathcal{N}(\\boldsymbol{\\mu}_x, \\boldsymbol{\\sigma}_x) \\lVert \\mathcal{N}(0, I)] && \\text{Compute variational loss}\n",
        "\\\\ \\\\\n",
        "\\text{L} &= \\text{recon. loss} + \\text{var. loss} && \\text{Combine losses}\n",
        "\\end{align}\n",
        "\n",
        "\\\\\n",
        "\n",
        "\\begin{aligned}\n",
        "\\text{KL}[\\mathcal{N}(\\mu_1, \\Sigma_1) \\lVert \\mathcal{N}(\\mu_2, \\Sigma_2))] &= \\\\ \n",
        "& \\frac{1}{2}\\left[\\log\\frac{|\\Sigma_2|}{|\\Sigma_1|} - d + \\text{tr} \\{ \\Sigma_2^{-1}\\Sigma_1 \\} + (\\mu_2 - \\mu_1)^T \\Sigma_2^{-1}(\\mu_2 - \\mu_1)\\right], \\text{where}~~d~~\\text{is the number of dimensions}\n",
        "\\end{aligned}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "sI-ZQU2FQlQu"
      },
      "outputs": [],
      "source": [
        "class ELBO(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(ELBO, self).__init__()\n",
        "\n",
        "  def compute_rec_error_(self, x: torch.Tensor, x_rec: torch.Tensor):\n",
        "    # implement reconstruction error\n",
        "    return F.binary_cross_entropy(x_rec, x, reduction='sum')\n",
        "  \n",
        "  def compute_kl_(sefl, z_mu: torch.Tensor, z_logvar: torch.Tensor):\n",
        "    # implement kl divergence (see above, think of what you're matching)\n",
        "    return 0.5 * torch.sum(torch.exp(z_logvar) + z_mu.pow(2) - - 1.0 - z_logvar)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, x_rec: torch.Tensor, \n",
        "              z_mu: torch.Tensor, z_logvar: torch.Tensor): \n",
        "\n",
        "    # reconstruction loss\n",
        "    recon_loss = self.compute_rec_error_(x, x_rec)\n",
        "\n",
        "    # kl divergence loss\n",
        "    kl_loss = self.compute_kl_(z_mu, z_logvar)\n",
        "\n",
        "    # total loss\n",
        "    loss = recon_loss + kl_loss\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "D38EzoMeNMof"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def eval(data_loader: DataLoader, model: VAE):\n",
        "    \n",
        "  # set the evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # test loss for the data\n",
        "  test_loss = 0\n",
        "  num_examples = 0\n",
        "\n",
        "  # define the ELBO loss function\n",
        "  loss = ELBO()\n",
        "\n",
        "  # we don't need to track the gradients, since we are not updating the \n",
        "  # parameters during evaluation / testing\n",
        "  with torch.no_grad():\n",
        "    for i, (x, _) in enumerate(data_loader):\n",
        "      # reshape the data\n",
        "      x = x.view(-1, 28 * 28)\n",
        "      x = x.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      x_rec, z_mu, z_logvar = model(x)\n",
        "\n",
        "      test_loss += loss(x, x_rec, z_mu, z_logvar).item()\n",
        "      num_examples += len(x)\n",
        "\n",
        "  return test_loss/num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xYXv6y97NCQ2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Train Loss: 126.31,         Test Loss: 125.45\n",
            "Epoch 1, Train Loss: 109.02,         Test Loss: 108.14\n",
            "Epoch 2, Train Loss: 102.47,         Test Loss: 101.76\n",
            "Epoch 3, Train Loss: 99.64,         Test Loss: 99.18\n",
            "Epoch 4, Train Loss: 97.27,         Test Loss: 96.97\n",
            "Epoch 5, Train Loss: 96.34,         Test Loss: 96.30\n",
            "Epoch 6, Train Loss: 95.13,         Test Loss: 95.18\n",
            "Epoch 7, Train Loss: 94.08,         Test Loss: 94.26\n",
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/rc/973wdqd91sq6bj8vj_ylcf900000gn/T/ipykernel_18701/367033775.py\", line 29, in <module>\n",
            "    optimizer.step()\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
            "    if \"_optimizer_load_state_dict_pre_hooks\" not in self.__dict__:\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
            "    # we need to graph break to ensure that aot respects the no_grad annotation.\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/optim/adam.py\", line 168, in step\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/optim/adam.py\", line 318, in adam\n",
            "    )\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/optim/adam.py\", line 443, in _single_tensor_adam\n",
            "    exp_avgs: List[Tensor],\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
            "    frames.append(self.format_record(record))\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
            "    frame_info.lines, Colors, self.has_colors, lvals\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
            "    return self._sd.lines\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
            "    pieces = self.included_pieces\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
            "    pos = scope_pieces.index(self.executing_piece)\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
            "    return only(\n",
            "  File \"/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
            "    raise NotOneValueFound('Expected one value, found 0')\n",
            "executing.executing.NotOneValueFound: Expected one value, found 0\n"
          ]
        }
      ],
      "source": [
        "encoder   = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM) # encoder\n",
        "decoder   = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM) # decoder\n",
        "model     = VAE(encoder, decoder).to(device) # vae\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)  # optizer\n",
        "loss_fun  = ELBO()\n",
        "\n",
        "for e in range(N_EPOCHS):\n",
        "\n",
        "  # set the train mode\n",
        "  model.train()\n",
        "  \n",
        "  for i, (x, _) in enumerate(train_iterator):\n",
        "      \n",
        "    # reshape the data into [batch_size, 784]\n",
        "    x = x.view(-1, 28 * 28).to(device)\n",
        "\n",
        "    # update the gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    x_rec, z_mu, z_logvar = model(x)\n",
        "\n",
        "    loss = loss_fun(x, x_rec, z_mu, z_logvar)\n",
        "    \n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Epoch {e}, Train Loss: {eval(train_iterator, model):.2f}, \\\n",
        "        Test Loss: {eval(test_iterator, model):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1qrESQnxe1x"
      },
      "source": [
        "# Example: sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mtPqUgqbNUkT"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Placeholder storage has not been allocated on MPS device!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "Cell \u001b[0;32mIn[8], line 32\u001b[0m, in \u001b[0;36mVAE.sample\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     29\u001b[0m   \n\u001b[1;32m     30\u001b[0m   \u001b[38;5;66;03m# implement sampling of num_samples datapoint\u001b[39;00m\n\u001b[1;32m     31\u001b[0m   z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc\u001b[38;5;241m.\u001b[39mz_dim)\n\u001b[0;32m---> 32\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/MLDL-Lab/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
          ]
        }
      ],
      "source": [
        "img = model.sample()\n",
        "img = img.view(28, 28)\n",
        "img = img.cpu().detach().numpy()\n",
        "\n",
        "plt.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pREZq-Kxgti"
      },
      "source": [
        "# Example: interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwf6wowxdvc"
      },
      "outputs": [],
      "source": [
        "number_one = train_dataset.data[train_dataset.targets == 1][0]\n",
        "number_five = train_dataset.data[train_dataset.targets == 5][0]\n",
        "\n",
        "with torch.no_grad():\n",
        "  one_mu, one_logvar = model.enc((number_one.view(-1, 28 * 28) / 255.).to(device))\n",
        "  z_one = model.reparameterization_trick(one_mu, one_logvar)\n",
        "  five_mu, five_logvar = model.enc((number_five.view(-1, 28 * 28) / 255.).to(device))\n",
        "  z_five = model.reparameterization_trick(five_mu, five_logvar)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 7, figsize=(21,3))\n",
        "  for n, i in enumerate(torch.linspace(0, 1, 7)):\n",
        "    predicted = model.dec(z_five * i + z_one * (1-i)).cpu()\n",
        "    ax[n].imshow(predicted.view(28,28))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vae.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLDL-Lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
